{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09db231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d748d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMAS = ['1.0','0.9','0.8','0.7','0.6','0.5']\n",
    "INDEX_TIME_UNIT = 1000 # number of tweets\n",
    "QUERY_TIME_UNIT = 1000 # number of tweets\n",
    "SIMILARITY_THRE = 0.5\n",
    "NUMBER_OF_RUNS = 3\n",
    "OUTPUT_DIR = \"./output_expm1/n9/\"\n",
    "\n",
    "def get_chance(gamma):\n",
    "    if gamma == '1.0':\n",
    "        return '100'\n",
    "    elif gamma == '0.9':\n",
    "        return '90'\n",
    "    elif gamma == '0.8':\n",
    "        return '80'\n",
    "    elif gamma == '0.7':\n",
    "        return '70'\n",
    "    elif gamma == '0.6':\n",
    "        return '60'\n",
    "    elif gamma == '0.5':\n",
    "        return '50'\n",
    "    \n",
    "def get_gamma_index(gamma):\n",
    "    if gamma == '1.0':\n",
    "        return 0\n",
    "    elif gamma == '0.9':\n",
    "        return 1\n",
    "    elif gamma == '0.8':\n",
    "        return 2\n",
    "    elif gamma == '0.7':\n",
    "        return 3\n",
    "    elif gamma == '0.6':\n",
    "        return 4\n",
    "    elif gamma == '0.5':\n",
    "        return 5\n",
    "    \n",
    "SUMMARY_INDEX = pd.Index(['Run', 'Chance', 'Index time unit', 'Query time unit', 'Similarity threshold', \n",
    "                 'Query counts', 'Indexed tweet counts', 'Index size'])\n",
    "SUMMARY_COL = ['Summary_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "QUERY_RESULT_COL = ['Result_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "QUERY_SIMILARITY_COL = ['Similarity_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "QUERY_LOOKUPS_COL = ['Lookups_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "INDEX_TIME_COL = ['Index_time_run{}_{}%'.format(str(i+1), get_chance(p)) for p in GAMMAS for i in range(NUMBER_OF_RUNS)]\n",
    "QUERY_TIME_COL = ['Query_time_run{}_{}%'.format(str(i+1), get_chance(p)) for p in GAMMAS for i in range(NUMBER_OF_RUNS)]\n",
    "\n",
    "FREQ_TABLES_X = ['Posting_list_length_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "QUERY_RECALL_X = ['Query_recall_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "QUERY_PRECISION_X = ['Query_precision_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "QUERY_LESS_LOOKUPS_X = ['Query_of_less_lookups_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "AVERAGE_LOOKUPS_X = ['Average_lookup_counts_' + get_chance(p) + '%' for p in GAMMAS]\n",
    "PLOT_X = [get_chance(p) + '%' for p in GAMMAS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158ac90",
   "metadata": {},
   "source": [
    "# Run Experiment  One and Read in Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32f693",
   "metadata": {},
   "source": [
    "* Use single terms to construct index\n",
    "* Each term has a 100% chance to 50% chance to be included in the index or fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfece70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSketchTweets(jar, index_time_unit, query_time_unit, chance_gamma, similarity_threshold, n, output_dir):\n",
    "    for run in range (1, n+1):\n",
    "        os.system(\"java -jar ./{}.jar -iu {} -qu {} -p {} -s {} -n {} -o {}\"\n",
    "        .format(jar, index_time_unit, query_time_unit, chance_gamma, similarity_threshold, run, output_dir))\n",
    "#         print(\"java -jar ./{}.jar -iu {} -qu {} -p {} -s {} -n {} -o {}\"\n",
    "#         .format(jar, index_time_unit, query_time_unit, chance_gamma, similarity_threshold, run, output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d895eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs the experiment and compares the results including:\n",
    "# - the size of the index and doc lists \n",
    "# - time for constructing the index and executing query \n",
    "# - number of lookups before finding the match\n",
    "\n",
    "def run_expm1():\n",
    "    for p in GAMMAS:\n",
    "        runSketchTweets(\"SketchingTweet-v1_n9\", INDEX_TIME_UNIT, QUERY_TIME_UNIT, p, SIMILARITY_THRE, NUMBER_OF_RUNS, OUTPUT_DIR)\n",
    "    results = load_expm1_csv(OUTPUT_DIR)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa16c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expm1_csv(directory):\n",
    "    '''\n",
    "    Returns a dictionary of results.\n",
    "    The dictionary keys are: summary, termfreq, query_results_similarity_lookups, index_time, query_time\n",
    "    '''\n",
    "    results = {}\n",
    "    summary = [0] * len(GAMMAS)\n",
    "    termfreq = [0] * len(GAMMAS)\n",
    "    query_result = [0] * len(GAMMAS)\n",
    "    query_similarity = [0] * len(GAMMAS)\n",
    "    query_lookups = [0] * len(GAMMAS)\n",
    "    index_time = [[0 for j in range(NUMBER_OF_RUNS)] for i in range(len(GAMMAS))]\n",
    "    query_time = [[0 for j in range(NUMBER_OF_RUNS)] for i in range(len(GAMMAS))]\n",
    "      \n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filename = re.match( r'Epoch_(\\d+)_iu_(\\d+)_qu_(\\d+)_p_(\\d+\\.\\d+)_s_([\\.\\d]+)_(.+).csv', file)  \n",
    "#             print(filename.group(3),filename.group(4),filename.group(5),filename.group(6))\n",
    "            name = filename.group(6)\n",
    "            gamma = filename.group(4)\n",
    "\n",
    "            if name == \"summary\":    \n",
    "                for p in GAMMAS:\n",
    "                    if gamma == p:\n",
    "                        summary[get_gamma_index(gamma)] = pd.read_csv(directory + \"/\" + file, header=None)\n",
    "\n",
    "            if name == \"term_freq\":\n",
    "                for p in GAMMAS:\n",
    "                    if gamma == p:\n",
    "                        termfreq[get_gamma_index(gamma)] = pd.read_csv(directory + \"/\" + file, header=None)\n",
    "                    \n",
    "            if name == \"query_result\":\n",
    "                for p in GAMMAS:\n",
    "                    if gamma == p:\n",
    "                        query_result[get_gamma_index(gamma)] = pd.read_csv(directory + \"/\" + file, header=None)\n",
    "                    \n",
    "            if name == \"query_similarity\":\n",
    "                for p in GAMMAS:\n",
    "                    if gamma == p:\n",
    "                        query_similarity[get_gamma_index(gamma)] = pd.read_csv(directory + \"/\" + file, header=None)\n",
    "                    \n",
    "            if name == \"lookups\":\n",
    "                for p in GAMMAS:\n",
    "                    if gamma == p:\n",
    "                        query_lookups[get_gamma_index(gamma)] = pd.read_csv(directory + \"/\" + file, header=None)\n",
    "            \n",
    "            if name == \"index_time\":\n",
    "                run = filename.group(1)\n",
    "                for p in GAMMAS:\n",
    "                    if gamma == p:\n",
    "                        for i in range(0,NUMBER_OF_RUNS):\n",
    "                            if run == str(i+1):\n",
    "                                index_time[get_gamma_index(gamma)][i] = pd.read_csv(directory + \"/\" + file, header=None)\n",
    "                    \n",
    "            if name == \"query_time\":\n",
    "                run = filename.group(1)\n",
    "                for p in GAMMAS:\n",
    "                    if gamma == p:\n",
    "                        for i in range(0,NUMBER_OF_RUNS):\n",
    "                            if run == str(i+1):\n",
    "                                query_time[get_gamma_index(gamma)][i] = pd.read_csv(directory + \"/\" + file, header=None)\n",
    "                  \n",
    "    \n",
    "    summary = pd.concat(summary, 1)\n",
    "    summary = summary.set_index(SUMMARY_INDEX)\n",
    "    summary.columns = SUMMARY_COL\n",
    "#     print(summary)\n",
    "    \n",
    "    for table in termfreq:\n",
    "        termfreq_index = table.iloc[:,0]\n",
    "        table.set_index(termfreq_index, inplace=True)\n",
    "        table.drop(table.columns[0], axis=1, inplace=True)\n",
    "        table.columns = ['number_of_terms', 'posting_count']\n",
    "#     print(termfreq)\n",
    "    \n",
    "    query_result = pd.concat(query_result, 1)\n",
    "    query_result.columns = QUERY_RESULT_COL\n",
    "#     print(query_result)\n",
    "    \n",
    "    query_similarity = pd.concat(query_similarity, 1)\n",
    "    query_similarity.columns = QUERY_SIMILARITY_COL\n",
    "#     print(query_similarity)\n",
    "\n",
    "    query_lookups = pd.concat(query_lookups, 1)\n",
    "    query_lookups.columns = QUERY_LOOKUPS_COL\n",
    "#     print(query_lookups)\n",
    "\n",
    "    query_result_similarity_lookup = [query_result, query_similarity, query_lookups]\n",
    "    query_result_similarity_lookup = pd.concat(query_result_similarity_lookup, 1)\n",
    "#     print(query_result_similarity_lookup)\n",
    "    \n",
    "    index_time_dfs = []\n",
    "    for p in index_time:\n",
    "        index_time_df = pd.concat(p, 1)\n",
    "        index_time_dfs.append(index_time_df)\n",
    "    index_time = pd.concat(index_time_dfs, 1)\n",
    "    index_time.columns = INDEX_TIME_COL\n",
    "    \n",
    "    query_time_dfs = []\n",
    "    for p in query_time:\n",
    "        query_time_df = pd.concat(p, 1)\n",
    "        query_time_dfs.append(query_time_df)\n",
    "    query_time = pd.concat(query_time_dfs, 1)\n",
    "    query_time.columns = QUERY_TIME_COL\n",
    "    \n",
    "    results['summary'] = summary\n",
    "    results['termfreq'] = termfreq\n",
    "    results['query_result_similarity_lookup'] = query_result_similarity_lookup\n",
    "    results['index_time'] = index_time\n",
    "    results['query_time'] = query_time\n",
    "  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_expm1() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280ff18",
   "metadata": {},
   "source": [
    "# Process Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21bfba-02fb-4dbd-b193-c6a0ca4d0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linechart(title, x, y, x_label, y_label, scale='linear'):\n",
    "    plt.plot(x, y)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.yscale(scale)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_scatter(title, x, y, x_label, y_label, scale='linear'):\n",
    "    plt.scatter(x, y, s=0.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.yscale(scale)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_barchart(title, x, y, x_label, y_label, color=\"#66B3BA\"):\n",
    "    layer = sns.barplot(x=x, y=y, color=color)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_boxplot(title, data, y_label, scale='linear'):\n",
    "    layer = sns.boxplot(data=data)\n",
    "    layer = sns.stripplot(data=data, color=\"orange\", jitter=0.2, size=1.5)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.yscale(scale)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197f85f",
   "metadata": {},
   "source": [
    "## Index size comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b864b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = results['summary']\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index size - number of posting lists\n",
    "def compare_index_size(sizes, title):\n",
    "    data = pd.to_numeric(sizes).to_list()\n",
    "    plot_barchart(title, PLOT_X, data, 'inclusion rate', 'number of posting lists')\n",
    "\n",
    "compare_index_size(summary.loc['Index size'], \"Index size - number of posting lists\")\n",
    "summary.loc['Index size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff24d24",
   "metadata": {},
   "source": [
    "## Documnet list length comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tables = results['termfreq']\n",
    "posting_list_length_distribution = [table['posting_count'].value_counts().sort_index(inplace=False) for table in freq_tables]\n",
    "total_posting_counts = [sum(table['posting_count']) for table in freq_tables]\n",
    "plot_barchart('Total number of postings in the index', PLOT_X, total_posting_counts, 'inclusion rate', 'number of postings')\n",
    "print('Total number of postings:')\n",
    "total_posting_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1ce0d-de82-4188-b439-d5997ceb29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_postinglist_length_distribution(PLOT_X, posting_list_length_distribution):\n",
    "    for i in range(len(PLOT_X)):\n",
    "        title = f'Posting list length distribution ({PLOT_X[i]} inclusion rate)'\n",
    "        x = posting_list_length_distribution[i].index\n",
    "        y = posting_list_length_distribution[i]\n",
    "        plot_scatter(title, x, y, 'posting list length', 'number of posting lists', scale='log')   \n",
    "compare_postinglist_length_distribution(PLOT_X, posting_list_length_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_posting_list_len(PLOT_X, freq_tables):\n",
    "    lengths = [table['posting_count'] for table in freq_tables]\n",
    "    avgs = [sum(l)/len(l) for l in lengths]\n",
    "    print(\"Average posting list length\")\n",
    "    print(avgs)\n",
    "#     index15 = [int(round(len(l)*0.15,0)) for l in lengths]\n",
    "#     index85 = [int(round(len(l)*0.85,0)) for l in lengths]\n",
    "#     nooutlier_lengths = [ lengths[i][index15[i]:index85[i]] for i in range(len(lengths))]\n",
    "    plot_boxplot(f'Average posting list length', lengths, 'posting list length', scale='log')\n",
    "    \n",
    "compare_posting_list_len(PLOT_X, freq_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9331f",
   "metadata": {},
   "source": [
    "## Query Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ff66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result_similarity_lookup = results['query_result_similarity_lookup']\n",
    "query_result_similarity_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c62864",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_true_similar = query_result_similarity_lookup[QUERY_RESULT_COL[0]] != -1\n",
    "true_similar = query_result_similarity_lookup[has_true_similar]\n",
    "num_true_similar = true_similar.shape[0]\n",
    "true_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_searches = []\n",
    "correct_searches = []\n",
    "for i in range(len(QUERY_RESULT_COL)):\n",
    "    is_correct_search = true_similar[QUERY_RESULT_COL[0]] == true_similar[QUERY_RESULT_COL[i]]\n",
    "    correct_search = true_similar[is_correct_search]\n",
    "    correct_searches.append(correct_search)\n",
    "    num_correct_searches.append(correct_search.shape[0])\n",
    "print('Number of true similar tweets that we found: ')\n",
    "num_correct_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed372fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_query_recall(recalls, title): \n",
    "    layer = sns.barplot(x=PLOT_X, y=recalls, color=\"#66B3BA\")\n",
    "    plt.title(title)\n",
    "    layer.set(ylabel='Percentage')\n",
    "    plt.show()\n",
    "\n",
    "recalls = []\n",
    "true_searches = []\n",
    "for i in range(len(num_correct_searches)):\n",
    "    true_searches.append(num_correct_searches[i])\n",
    "    recall = round((num_correct_searches[i]/num_true_similar) * 100, 2)\n",
    "    recalls.append(recall)\n",
    "    chance = PLOT_X[i]\n",
    "    print('Using {} of terms, we can find {}% truly similar tweets'.format(chance, recall))\n",
    "    \n",
    "compare_query_recall(recalls, 'Query recall - percentage of the truly similar tweets we can find')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51d11f",
   "metadata": {},
   "source": [
    "## Query Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_predict_similar = query_result_similarity_lookup['Result_75%'] != -1\n",
    "# predict_similar = query_result_similarity_lookup[is_predict_similar]\n",
    "# num_predict_similar = predict_similar.shape[0]\n",
    "# predict_similar\n",
    "num_predict_similar_lst = []\n",
    "predict_similar_lst = []\n",
    "for i in range(len(QUERY_RESULT_COL)):\n",
    "    is_predict_similar = query_result_similarity_lookup[QUERY_RESULT_COL[i]] != -1\n",
    "    predict_similar = query_result_similarity_lookup[is_predict_similar]\n",
    "    predict_similar_lst.append(predict_similar)\n",
    "    num_predict_similar_lst.append(predict_similar.shape[0])\n",
    "print(\"The number of tweets that we think are similar: \")\n",
    "num_predict_similar_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_query_precision(precisions, title): \n",
    "    layer = sns.barplot(x=PLOT_X, y=precisions, color=\"#66B3BA\")\n",
    "    layer.set(ylabel='Percentage')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "precisions = []\n",
    "for i in range(len(num_predict_similar_lst)):\n",
    "    precision = round((num_correct_searches[i]/num_predict_similar_lst[i]) * 100, 2)\n",
    "    precisions.append(precision)\n",
    "    chance = PLOT_X[i]\n",
    "    print('Using {} of terms, {}% tweets that we found similar are truly similar tweets'.format(chance, precision))\n",
    "    \n",
    "compare_query_precision(precisions, 'Query Precision - Percentage of tweets that we can think are similar are truly similar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f6b80",
   "metadata": {},
   "source": [
    "## Number of searches that need fewer lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b70089",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_of_less_lookups = []\n",
    "less_search_lst = []\n",
    "for i in range(len(QUERY_LOOKUPS_COL)):\n",
    "    if i != 0:\n",
    "        is_less_search = correct_searches[i][QUERY_LOOKUPS_COL[0]] > correct_searches[i][QUERY_LOOKUPS_COL[i]]\n",
    "        less_search = correct_searches[i][is_less_search]\n",
    "        less_search_lst.append(less_search)\n",
    "        query_of_less_lookups.append(less_search.shape[0])\n",
    "    else:\n",
    "        less_search_lst.append(None)\n",
    "        query_of_less_lookups.append(0)\n",
    "print(\"The number of tweets that need less lookups before correctly finding the true similar tweets: \")\n",
    "query_of_less_lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0185ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_number_of_tweets_need_less_lookups(reduces, title): \n",
    "    layer = sns.barplot(x=PLOT_X[1:], y=reduces, color=\"#66B3BA\")\n",
    "    layer.set(ylabel='Percentage')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "proportions = []\n",
    "for i in range(len(query_of_less_lookups)):\n",
    "    proportion = round((query_of_less_lookups[i] / num_correct_searches[i]) * 100, 2)\n",
    "    proportions.append(proportion)\n",
    "    chance = PLOT_X[i]\n",
    "    print('Using {} of terms, {}% queries need less lookups before correctly finding the true similar tweets'.format(chance, proportion))\n",
    "    \n",
    "compare_number_of_tweets_need_less_lookups(proportions[1:], ' Proportion of queries that need less lookups before correctly finding the true similar tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d7430",
   "metadata": {},
   "source": [
    "## Number of average lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e192340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_number_of_avg_lookups(reduces, title): \n",
    "    layer = sns.barplot(x=PLOT_X, y=reduces, color=\"#66B3BA\")\n",
    "    layer.set(ylabel='Counts')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "avg_lookups = []\n",
    "for i in range(len(QUERY_LOOKUPS_COL)):\n",
    "    avg_lookup = np.average(np.array(correct_searches[i][QUERY_LOOKUPS_COL[i]]))\n",
    "    avg_lookups.append(avg_lookup)\n",
    "\n",
    "compare_number_of_avg_lookups(avg_lookups, 'The number of average lookups required before correctly finding a true similar tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduces = []\n",
    "print('Comparing to using all the terms:')\n",
    "for i in range(len(avg_lookups)):\n",
    "    if i != 0:\n",
    "        reduce = round(((avg_lookups[0] - avg_lookups[i]) / avg_lookups[0]) * 100, 2)\n",
    "        reduces.append(reduce)\n",
    "        chance = PLOT_X[i]\n",
    "        print('By using {} of terms, {}% of less lookups are needed for correctly finding a true similar tweets'.format(chance, reduce))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f40c5a",
   "metadata": {},
   "source": [
    "## Index time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e4779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_time = results['index_time']\n",
    "index_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_time(avg_time, title): \n",
    "    layer = sns.barplot(x=PLOT_X, y=avg_time, color=\"#66B3BA\")\n",
    "    layer.set(ylabel='Milliseconds')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "index_time_avgs = []\n",
    "for col in index_time.columns:\n",
    "    index_time_avgs.append(np.average(np.array(index_time[col])))\n",
    "\n",
    "index_time_avgs2 = []\n",
    "c = 0\n",
    "acc = 0\n",
    "for avg in index_time_avgs:\n",
    "    if c < 2:\n",
    "        acc += avg\n",
    "        c += 1\n",
    "        \n",
    "    else:\n",
    "        acc += avg\n",
    "#         print(acc)\n",
    "        index_time_avgs2.append(round(acc/3 , 4))\n",
    "        acc = 0\n",
    "        c = 0\n",
    "\n",
    "for i in range(len(index_time_avgs2)):\n",
    "    print('By using {} of terms, the average time for indexing {} tweets is {} milliseconds'.format(PLOT_X[i], INDEX_TIME_UNIT, index_time_avgs2[i]))\n",
    "compare_time(index_time_avgs2, 'Average time for indexing {} tweets'.format(INDEX_TIME_UNIT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff571abd",
   "metadata": {},
   "source": [
    "## Query time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_time = results['query_time']\n",
    "query_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_time_avgs = []\n",
    "for col in query_time.columns:\n",
    "    query_time_avgs.append(np.average(np.array(query_time[col])))\n",
    "\n",
    "query_time_avgs2 = []\n",
    "c = 0\n",
    "acc = 0\n",
    "for avg in query_time_avgs:\n",
    "    if c < 2:\n",
    "        acc += avg\n",
    "        c += 1\n",
    "        \n",
    "    else:\n",
    "        acc += avg\n",
    "#         print(acc)\n",
    "        query_time_avgs2.append(round(acc/3 , 4))\n",
    "        acc = 0\n",
    "        c = 0\n",
    "\n",
    "for i in range(len(query_time_avgs2)):\n",
    "    print('By using {} of terms, the average time for querying {} tweets is {} milliseconds'.format(PLOT_X[i], INDEX_TIME_UNIT, query_time_avgs2[i]))\n",
    "compare_time(query_time_avgs2, 'Average time for querying {} tweets'.format(INDEX_TIME_UNIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57acd7-b641-47a3-b7ee-3c6df0da998c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
